{
    "version": 40,
    "schema": {
        "age": "catalogue",
        "workclass": "catalogue",
        "fnlwgt": "numeric",
        "education": "catalogue",
        "education-num": "numeric",
        "marital-status": "catalogue",
        "occupation": "catalogue",
        "relationship": "catalogue",
        "race": "catalogue",
        "sex": "catalogue",
        "capital-gain": "numeric",
        "capital-loss": "numeric",
        "hours-per-week": "numeric",
        "native-country": "catalogue",
        "income": "catalogue"
    },
    "_label": "age",
    "train_result": {
        "valid_result": {},
        "accuracy": 0.4454772531837353,
        "precision": 0.4363188554149464,
        "recall_score": 0.4454772531837353,
        "f1": 0.43304176527726684
    },
    "test_result": {
        "test_1": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_2": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_3": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_4": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_5": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_6": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_7": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_8": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_9": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_10": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_11": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_12": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_13": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_14": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_15": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_16": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_17": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_18": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_19": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_20": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_21": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_22": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_23": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_24": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_25": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_26": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_27": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_28": {
            "accuracy": 0.42827868852459017,
            "precision": 0.404651849990282,
            "recall_score": 0.42827868852459017,
            "f1": 0.4118084988736779
        },
        "test_29": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_30": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_31": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_32": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_33": {
            "accuracy": 0.4454772531837353,
            "precision": 0.4363188554149464,
            "recall_score": 0.4454772531837353,
            "f1": 0.43304176527726684
        },
        "test_34": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_35": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_36": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_37": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_38": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_39": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        },
        "test_40": {
            "accuracy": 0.44081632653061226,
            "precision": 0.4356062088150669,
            "recall_score": 0.44081632653061226,
            "f1": 0.4241705142610575
        }
    }
}